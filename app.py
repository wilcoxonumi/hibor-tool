import streamlit as st
import requests
import pandas as pd
import matplotlib.pyplot as plt
from datetime import date

# === 0. [æ–°å¢] å­—ä½“è®¾ç½® (è§£å†³å›¾ä¾‹ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜) ===
# å°è¯•è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œè§£å†³ matplotlib é»˜è®¤æ— æ³•æ˜¾ç¤ºä¸­æ–‡çš„é—®é¢˜
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS', 'sans-serif'] 
plt.rcParams['axes.unicode_minus'] = False # è§£å†³è´Ÿå·æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜

# === 1. é¡µé¢åŸºæœ¬é…ç½® ===
st.set_page_config(page_title="HKMA æ•°æ®", layout="wide")
st.title("ğŸ‡­ğŸ‡° HKMA é‡‘èæ•°æ®æå–å·¥å…·")

# === 2. å®šä¹‰æ•°æ®æºé…ç½® (å·²ä¿®æ­£ï¼šåªä¿ç•™3ä¸ªæ¥å£) ===
API_CONFIG = {
    "HIBOR (é¦™æ¸¯é“¶è¡ŒåŒä¸šæ‹†æ¯)": {
        "url": "https://api.hkma.gov.hk/public/market-data-and-statistics/monthly-statistical-bulletin/er-ir/hk-interbank-ir-daily",
        "segment": "hibor.fixing",
        "date_col": "end_of_day",
        "title_en": "HIBOR Interest Rates - Daily",
        "doc_url": "https://apidocs.hkma.gov.hk/gb_chi/documentation/market-data-and-statistics/monthly-statistical-bulletin/er-ir/hk-interbank-ir-daily/"
    },
    "RMB Deposit Rates (äººæ°‘å¸å­˜æ¬¾åˆ©ç‡)": {
        "url": "https://api.hkma.gov.hk/public/market-data-and-statistics/monthly-statistical-bulletin/er-ir/renminbi-dr",
        "segment": None,
        "date_col": "end_of_month",
        "title_en": "RMB Deposit Rates",
        "doc_url": "https://apidocs.hkma.gov.hk/gb_chi/documentation/market-data-and-statistics/monthly-statistical-bulletin/er-ir/renminbi-dr/"
    },
    "Monetary Statistics (è´§å¸ç»Ÿè®¡)": {
        "url": "https://api.hkma.gov.hk/public/market-data-and-statistics/monthly-statistical-bulletin/financial/monetary-statistics",
        "segment": None,
        "date_col": "end_of_month",
        "title_en": "Monetary Statistics (M1/M2/M3)",
        "doc_url": "https://apidocs.hkma.gov.hk/gb_chi/documentation/market-data-and-statistics/monthly-statistical-bulletin/financial/monetary-statistics/"
    }
}

# === 3. è¯»å– CSV é…ç½® ===
@st.cache_data
def load_variable_meta():
    try:
        # ç›´æ¥è¯»å–æ ‡å‡† CSV
        df_meta = pd.read_csv("variable_config.csv")
        # å»é‡
        df_meta = df_meta.drop_duplicates(subset=['variable'])
        # è½¬å­—å…¸
        return df_meta.set_index('variable').to_dict(orient='index')
    except Exception as e:
        st.warning("âš ï¸ æç¤º: ç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ° variable_config.csvï¼Œå°†æ˜¾ç¤ºåŸå§‹è‹±æ–‡ä»£ç ã€‚")
        return {}

VARIABLE_META = load_variable_meta()

def get_display_info(var_name):
    """è·å–å˜é‡çš„ä¸­æ–‡åå’Œå•ä½"""
    info = VARIABLE_META.get(var_name, {"label": var_name, "unit": ""})
    if pd.isna(info.get('unit')): info['unit'] = ""
    if pd.isna(info.get('label')): info['label'] = var_name
    return info

# === 4. åˆå§‹åŒ– Session State ===
if 'df_all' not in st.session_state:
    st.session_state['df_all'] = None
if 'current_source' not in st.session_state:
    st.session_state['current_source'] = ""

# === 5. ä¾§è¾¹æ ï¼šæ§åˆ¶é¢æ¿ ===
with st.sidebar:
    st.header("1. æ•°æ®æºè®¾ç½®")
    
    selected_source_name = st.selectbox("é€‰æ‹©æ•°æ®ç±»å‹", options=list(API_CONFIG.keys()))
    current_config = API_CONFIG[selected_source_name]
    
    st.divider()
    st.info(f"è®¾ç½® {selected_source_name} çš„æŠ“å–èŒƒå›´")
    
    earliest_date = date(1990, 1, 1)
    default_start = date(date.today().year - 1, 1, 1)
    
    fetch_start = st.date_input("æŠ“å–å¼€å§‹æ—¥æœŸ", value=default_start, min_value=earliest_date, max_value=date.today())
    fetch_end = st.date_input("æŠ“å–ç»“æŸæ—¥æœŸ", value=date.today(), min_value=earliest_date, max_value=date.today())
    
    fetch_btn = st.button("ğŸš€ ç‚¹å‡»æå–æ•°æ®", type="primary")

# === 6. æ•°æ®æå–å‡½æ•° ===
@st.cache_data
def fetch_hkma_data(api_url, segment, start_str, end_str):
    pagesize = 1000
    offset = 0
    all_records = []
    placeholder = st.empty()
    target_start = pd.to_datetime(start_str)
    target_end = pd.to_datetime(end_str)
    
    while True:
        placeholder.text(f"æ­£åœ¨è¯»å– HKMA æ¥å£... Offset: {offset}")
        params = {"pagesize": pagesize, "offset": offset, "from": start_str, "to": end_str}
        if segment: params["segment"] = segment
            
        try:
            response = requests.get(api_url, params=params)
            response.raise_for_status()
            data = response.json()
            records = data.get("result", {}).get("records", [])
            if not records: break
            all_records.extend(records)
            offset += pagesize
        except Exception as e:
            st.error(f"API è¯·æ±‚å¤±è´¥: {e}")
            break
            
    placeholder.empty()
    if not all_records: return pd.DataFrame()
    
    df = pd.DataFrame(all_records)
    
    # æ¸…æ´—æ—¥æœŸ
    date_col_found = None
    possible_date_cols = ['end_of_day', 'end_of_month', 'date', 'observation_date']
    for col in possible_date_cols:
        if col in df.columns:
            date_col_found = col
            break
            
    if date_col_found:
        df[date_col_found] = pd.to_datetime(df[date_col_found], errors='coerce')
        df = df.dropna(subset=[date_col_found])
        mask = (df[date_col_found] >= target_start) & (df[date_col_found] <= target_end)
        df = df.loc[mask].sort_values(date_col_found)
